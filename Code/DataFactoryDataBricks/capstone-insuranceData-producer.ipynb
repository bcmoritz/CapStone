{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F\nimport os.path\nimport json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"654b3f91-65c4-46d8-b3de-665d15f579a9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["def error_cb(err):\n    \"\"\" The error callback is used for generic client errors. These\n        errors are generally to be considered informational as the client will\n        automatically try to recover from all errors, and no extra action\n        is typically required by the application.\n        For this example however, we terminate the application if the client\n        is unable to connect to any broker (_ALL_BROKERS_DOWN) and on\n        authentication errors (_AUTHENTICATION). \"\"\"\n\n    print(\"Client error: {}\".format(err))\n    if err.code() == KafkaError._ALL_BROKERS_DOWN or \\\n       err.code() == KafkaError._AUTHENTICATION:\n        # Any exception raised from this callback will be re-raised from the\n        # triggering flush() or poll() call.\n        raise KafkaException(err)\n\n\ndef acked(err, msg):\n    \"\"\" \n        Error callback is used for generic issues for producer errors. \n        \n        Parameters:\n            err (err): Error flag.\n            msg (str): Error message that was part of the callback.\n    \"\"\"\n    if err is not None:\n        print(\"Failed to deliver message: %s: %s\" % (str(msg), str(err)))\n    else:\n        print(\"Message produced: %s\" % (str(msg)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Error Functions","showTitle":true,"inputWidgets":{},"nuid":"5b5c55fe-5824-4405-be81-fb2e1649a208"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from confluent_kafka import Consumer\nfrom time import sleep\nimport uuid\nfrom confluent_kafka import Producer, Consumer, KafkaError, KafkaException\nfrom confluent_kafka.admin import AdminClient, NewTopic\n\n\n#KAFKA variables, Move to the OS variables or configuration\n# This will work in local Jupiter Notebook, but in a databrick, hiding config.py is tougher. \nconfluentClusterName = \"stage3talent\"\nconfluentBootstrapServers = \"pkc-ldvmy.centralus.azure.confluent.cloud:9092\"\nconfluentTopicName = \"insurance\"\nschemaRegistryUrl = \"https://psrc-gq7pv.westus2.azure.confluent.cloud\"\nconfluentApiKey = \"YHMHG7E54LJA55XZ\"\nconfluentSecret = \"/XYn+w3gHGMqpe9l0TWvA9FznMYNln2STI+dytyPqtZ9QktH0TbGXUqepEsJ/nR0\"\nconfluentRegistryApiKey = \"YHMHG7E54LJA55XZ\"\nconfluentRegistrySecret = \"/XYn+w3gHGMqpe9l0TWvA9FznMYNln2STI+dytyPqtZ9QktH0TbGXUqepEsJ/nR0\"\n\nadmin_client = AdminClient({\n    'bootstrap.servers': confluentBootstrapServers,\n    'sasl.mechanism': 'PLAIN',\n    'security.protocol': 'SASL_SSL',\n    'sasl.username': confluentApiKey,\n    'sasl.password': confluentSecret,\n    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n    'auto.offset.reset': 'earliest',\n    'error_cb': error_cb,\n})\n\ntopic_list = []\n\ntopic_list.append(NewTopic(\"insurance\", 1, 3))\nadmin_client.create_topics(topic_list)\nfutures = admin_client.create_topics(topic_list)\n\n\ntry:\n    record_metadata = []\n    for k, future in futures.items():\n        # f = i.get(timeout=10)\n        print(f\"type(k): {type(k)}\")\n        print(f\"type(v): {type(future)}\")\n#         print(future.result())\n\nexcept KafkaError:\n    # Decide what to do if produce request failed...\n    print(traceback.format_exc())\n    result = 'Fail'\nfinally:\n    print(\"finally\")\n\n# Kakfa Class Setup.\np = Producer({\n    'bootstrap.servers': confluentBootstrapServers,\n    'sasl.mechanism': 'PLAIN',\n    'security.protocol': 'SASL_SSL',\n    'sasl.username': confluentApiKey,\n    'sasl.password': confluentSecret,\n    'group.id': str(uuid.uuid1()),  # this will create a new consumer group on each invocation.\n    'auto.offset.reset': 'earliest',\n    'error_cb': error_cb,\n})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Set up producer class and topic","showTitle":true,"inputWidgets":{},"nuid":"bdec2762-4a27-4911-8fde-ec2d1194dfb9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">type(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nfinally\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">type(k): &lt;class &#39;str&#39;&gt;\ntype(v): &lt;class &#39;concurrent.futures._base.Future&#39;&gt;\nfinally\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["###### Mount Point 1 through Oauth security.https://adb-593121260067740.0.azuredatabricks.net/?o=593121260067740#\nstorageAccount = \"gen10dbcdatalake\"\nstorageContainer = \"group3-capstone\"\nclientSecret = \"~bJ7Q~KslVT~sAmHkOLXL0oeTp1ZkAcndtHPr\"\nclientid = \"2ca50102-5717-4373-b796-39d06568588d\"\nmount_point = \"/mnt/group3\"\n\n\nconfigs = {\"fs.azure.account.auth.type\": \"OAuth\",\n       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n       \"fs.azure.account.oauth2.client.id\": clientid,\n       \"fs.azure.account.oauth2.client.secret\": clientSecret,\n       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/d46b54b2-a652-420b-aa5a-2ef7f8fc706e/oauth2/token\",\n       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n\n# try: \n#     dbutils.fs.unmount(mount_point)\n# except:\n#     pass\n\n# dbutils.fs.mount(\n# source = \"abfss://\"+storageContainer+\"@\"+storageAccount+\".dfs.core.windows.net/\",\n# mount_point = mount_point,\n# extra_configs = configs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Set up connection to container to access cleaned csv files","showTitle":true,"inputWidgets":{},"nuid":"b2a59c77-592b-42b6-adc0-a91685c15a8e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["df = spark.read.csv(\"/mnt/group3/CleanedInsuranceData/*.csv\", header = \"true\")\n# print(type(df.rdd.collect())), List\n# print(len(df.rdd.collect())), 59381\n# print(df.rdd.collect()[59380].asDict())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Access cleaned CSV files","showTitle":true,"inputWidgets":{},"nuid":"1d3bd0fb-18d2-4c0d-ab01-a98b525a77f4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["display(df)\nprint(df.count(),len(df.columns))\ndf_agg = df.agg(*[F.count(F.when(F.isnull(c), c)).alias(c) for c in df.columns])\ndisplay(df_agg)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Checking the data for any data loss or something","showTitle":true,"inputWidgets":{},"nuid":"bafca739-3d1c-40b1-9264-93e5500f7a5a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["import json\n# import random\n\n\n# for i in range(df.count()):\n#     df2 = df.sample(withReplacement=False, fraction=0.01).limit(1)\n#     df_dict = df2.toPandas().to_dict(orient=\"records\")[0]\n#     print(len(df_dict))\n#     print(df_dict)\n#     p.produce(\"insurance\", json.dumps(df_dict))\n#     p.flush()\n#     sleep(0.50)\ni = 0\nfor row in df.rdd.collect():\n#     print(type(row))\n    row_d = row.asDict()#, Pyspark: Convert pyspark.sql.row into Dataframe\n#     print(type(row_d)), dict\n#     print(len(row_d)), 135\n    i += 1\n#     print(row_d)\n    p.produce(\"insurance\", json.dumps(row_d))\n    p.flush()\n#     sleep(0.50)\n\n\nprint(i)#, 59381"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"Sending messages","showTitle":true,"inputWidgets":{},"nuid":"9f5921ac-8407-4375-ba36-bf0d8e4a2cb4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">59381\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">59381\n</div>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"capstone-insuranceData-producer","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":164542636741848}},"nbformat":4,"nbformat_minor":0}
